---
title: "hw-03"
author: "Qinhao Feng S2711578"
date: "`r Sys.Date()`"
output: html_document
---



```{r setup, include=FALSE}
## **DO NOT EDIT THIS CODE CHUNK**
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidymodels)
```


## Data load and preparation before modelling

```{r read_data}
gss16<-read.csv("data/gss16.csv")
```

#### Cleaning and selecting columns

```{r}
gss16_advfront <- gss16 %>%
  select(advfront, emailhr, educ, polviews, wrkstat) %>%
  drop_na()
```

#### Re-levelling `advfront`

```{r}
gss16_advfront <- gss16_advfront %>%
  mutate(
    advfront = case_when(
      advfront == "Strongly agree" ~ "Agree",
      advfront == "Agree" ~ "Agree",
      TRUE ~ "Not agree"
    ),
    advfront = fct_relevel(advfront, "Not agree", "Agree")
  )
```

#### Re-levelling `polviews`

```{r}
gss16_advfront <- gss16_advfront %>%
  mutate(
    polviews = case_when(
      str_detect(polviews, "[Cc]onservative") ~ "Conservative",
      str_detect(polviews, "[Ll]iberal") ~ "Liberal",
      TRUE ~ polviews
    ),
    polviews = fct_relevel(polviews, "Conservative", "Moderate", "Liberal")
  )
```

#### Creating a new `fulltime` variable

```{r}
gss16_advfront <- gss16_advfront %>%
  mutate(fulltime = ifelse(wrkstat == "Working fulltime",TRUE,FALSE))
```


## Exercise 1: Create a linear regression model

#### Exercise 1 (a)

```{r}
model <- lm(emailhr ~ educ + fulltime, data = gss16_advfront)
summary(model)
```

*The formula of best fit line is y = −3.3516+0.5376⋅educ+5.2796⋅fulltimeTRUE. fulltimeTRUE shows the difference in emailhr for full-time workers compared to others. When a person is employed full-time, the predicted value of the dependent variable increases by 5.2796 units compared to someone who is not employed full-time. *

#### Exercise 1 (b)

```{r}
glance(model)
# Data Visualization
ggplot(data = model, aes(.fitted, .resid)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Residuals vs Fitted")
# Q-Q plot
plot(model, which = 2)
```

*(1)r.squared values below 0.1, suggesting that the model does not explain much of the variation in the outcome variable. (2) The residual plot shows a horizontal line, with points evenly scattered around it, which indicates that the residuals is randomly distributed around zero, he linear model assumptions are satistied. (3) If the residuals follow a normal distribution, the points on the Q-Q plot should roughly align along the diagonal line. However, it didn't, hence model is not very applicable.*

## Exercise 2: Create a workflow to fit a model

```{r split-data}
set.seed(1234)
gss16_split <- initial_split(gss16_advfront)
gss16_train <- training(gss16_split)
gss16_test  <- testing(gss16_split)
```

#### Exercise 2 (a)

```{r}
# Data Splitting
set.seed(1234)
gss16_split <- initial_split(gss16_advfront)
gss16_train <- training(gss16_split)
gss16_test  <- testing(gss16_split)
# Recipe
gss16_rec_1 <- recipe(advfront ~ educ, data = gss16_train)
# Model
gss16_mod_1 <- logistic_reg() %>%
  set_engine("glm")
# Workflow
gss16_wflow_1 <- workflow() %>%
  add_recipe(gss16_rec_1) %>%
  add_model(gss16_mod_1)
```

*Your answer here*

#### Exercise 2 (b)

```{r}

```

*The variable appears to be binary.*

#### Exercise 2 (c)

```{r}
# Fit model to training data
gss16_fit_1 <- gss16_wflow_1 %>%
  fit(data = gss16_train)
# Output
tidy(gss16_fit_1)
```

*Your answer here*

## Exercise 3: Logistic regression with single predictor

#### Exercise 3 (a)

```{r}
# replace this with your code
```

*Your answer here*

#### Exercise 3 (b)

```{r}
# replace this with your code
```

*Your answer here*

## Exercise 4: Logistic regression modelling and interpretation

#### Exercise 4 (a)

```{r}
# replace this with your code
```

*Your answer here*

#### Exercise 4 (b)
  
```{r}
# replace this with your code
```

*Your answer here*

#### Exercise 4 (c) 

```{r}
# replace this with your code
```

*Your answer here*

